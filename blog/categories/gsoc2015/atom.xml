<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Gsoc2015 | Pony's Stable]]></title>
  <link href="http://chienlima.github.io/blog/categories/gsoc2015/atom.xml" rel="self"/>
  <link href="http://chienlima.github.io/"/>
  <updated>2015-07-04T23:53:28+08:00</updated>
  <id>http://chienlima.github.io/</id>
  <author>
    <name><![CDATA[Chienli Ma]]></name>
    <email><![CDATA[maqianlie@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Evaluation Passed and the Next Step: OpFromGraph]]></title>
    <link href="http://chienlima.github.io/blog/2015/07/04/newpost/"/>
    <updated>2015-07-04T23:51:57+08:00</updated>
    <id>http://chienlima.github.io/blog/2015/07/04/newpost</id>
    <content type="html"><![CDATA[<p>Evaluation passed and the next step: OpFromGraph</p>

<p>The PR of <code>function.copy()</code> is ready to merged, only need fred to fix a small bug. And in this Friday I passed the mid-term evaluation. So it&rsquo;s time to take the next step.</p>

<p>In the original proposal ,the next step is to <code>swap output and updates</code>. After a discussion with Fred, we thought this feature is useless so we skip this and head to the next feature directly &ndash; <code>OpFromGraph</code>.</p>

<h2>Goal: </h2>

<p>make class <code>OpFromGraph</code> work.</p>

<h2>Big How?</h2>

<p> <code>OpFromGraph</code> should init a <code>gof.op</code> that has no difference with other <code>Op</code>s and can be optimized. Otherwise it has no sense.</p>

<p>For this, we need to make it work on GPU, make sure it works with C code and document it. Make sure <code>infer_shape()</code>, <code>grad()</code> work with it. Ideally, make <code>R_op()</code> work too.</p>

<h2>Detailed how.</h2>

<ul>
<li>Implement <code>__hash__()</code> and <code>__eq__()</code> method so it is a basic</li>
<li>Implement <code>infer_shape()</code> method so that it&rsquo;s optimizable</li>
<li>test if it work with shared variable as input and if not make it work. Add test for that.</li>
<li>Move it correctly to the GPU. We can do it quickly for the old back-end, move all float32 inputs to the GPU. Otherwise, we need to compile the inner function, see which inputs get moved to the GPU, then create a new OpFromGraph with the corresponding input to the GPU. <a href="https://github.com/Theano/Theano/pull/2982">#2982</a></li>
<li>Maker<code>grad()</code> work. This should remove the grad_depth parameter</li>
</ul>


<hr />

<h3>First Step: infer_shape:</h3>

<p>The main idea is to calculatet the shapes of outputs from given input shapes. This is a process similar to executing a function &ndash; we cannot know the shape of a variable before knowing the shape of the variables it depends on. So, we can mimic the <code>make_thunk()</code> method to calculate the shape from output to input. I come out with a draft now, and need some help with test case.</p>

<pre><code class="python">order = self.fn.maker.fgraph.toposort()

# A dict that map variable to its shape(list)
shape_map = {}

# set the input shape of the fgraph
for in_var, shape in izip(in_vars, shapes);
    shape_map.set_default(in_var, shape)

# calculate the output shape from input shape
for node in order:
    assert all([var in shape_map.keys() for var in node.inputs])

    # calculate output shape
    in_shapes = [ shape_map[var] for var in node.inputs]
    out_shapes = node.op.infer_shape(node, in_shapes)

    # store the shape of that variable
    for out_var, shape in izip(node.outputs, out_shapes):
        shape_map.set_default(out_var, list(shape))

# extract output shape
return [ tuple(shape_map[var]) for var in fgraph.outputs]
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Second Two-week]]></title>
    <link href="http://chienlima.github.io/blog/2015/06/21/the-second-two-week/"/>
    <updated>2015-06-21T00:09:54+08:00</updated>
    <id>http://chienlima.github.io/blog/2015/06/21/the-second-two-week</id>
    <content type="html"><![CDATA[<p>Almost forget to update a post.</p>

<p>In this two week, I finished the first feature &ldquo;Allow user to regenerate a function from compiled one&rdquo;, and this feature &ldquo;can be merged. But there&rsquo;s another PR need to rebase.&rdquo;  So, it&rsquo;s done.</p>

<p>Also, I get a draft of the code that allow user to swap SharedVariable. When I said &lsquo;draft&rsquo;, I mean that I&rsquo;ve finish the code as well as the testcase and they work. I&rsquo;ll make a PR for review at the beginning of next week. Also I have some new idea need to discuss with Fred.</p>

<p>I hope I can finish all 3 feature in the first 6-week: copy, swap_sharedvariable and delete_update. So that I can focus on OpFromGraph in the next half. It seems that someone has started working on it now. I hope he did not &lsquo;rob&rsquo; my job. :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Second_look_into_Theano_core]]></title>
    <link href="http://chienlima.github.io/blog/2015/05/17/second-look-into-theano-core/"/>
    <updated>2015-05-17T19:26:55+08:00</updated>
    <id>http://chienlima.github.io/blog/2015/05/17/second-look-into-theano-core</id>
    <content type="html"><![CDATA[<p>The first feature was done and is being reviewed! This post is my reading notes of theano core this week and how I implements the share_memory feature.</p>

<h2>Data sturctures</h2>

<h3>Function</h3>

<pre><code>Function is a callable object whose core is a function ```fn``` generate by linker. Every time a function is call, it will first examinate input data and then evaluate the ```fn``` to get output value.
</code></pre>

<p>PARAMETERS:</p>

<ul>
<li><strong>input/output_storages:</strong> two list of Container instance.</li>
<li><strong>maker:</strong> the maker of this function</li>
<li><strong>finder/inv_finder:</strong> provide mapping between <code>Container</code> and <code>In</code>( seems useless )</li>
<li><strong>fn:</strong> Core, what the real &lsquo;function&rsquo; is, a python function that evaluate graph.</li>
<li><strong>default and indices:</strong> List of tuples, partially useful. <code>default[i][2]</code> is <code>input_storage[i]</code> ;  <code>indices[i][0]</code> is <code>inputs[i]</code> in FunctionMaker.</li>
</ul>


<p>METHODS:</p>

<ul>
<li><code>__init__()</code>: Initialize input containers value and set up &ldquo;[]&rdquo; operator of container and self</li>
<li><code>__call__()</code>: verify input data types and then execute the <code>self.fn</code>. Pickup value in some of the the output storages and set up corresponding input_storage in there&rsquo;s updates.</li>
</ul>


<hr />

<h3>FunctionMaker</h3>

<pre><code>FunctionMaker is a Factory that create function. However, it's not like a factory very much cause every maker only corrsponds to one function. In FunctionMaker some important info of a theano.function are stored, such as Inputs/Outputs(represented by SymbolicKit), FunctionGraph.
</code></pre>

<p>PARAMS:</p>

<ul>
<li><strong>indices:</strong> ( almost deprecated, ignore )</li>
<li><strong>inputs:</strong> List of In() instances. In()</li>
<li><strong>output:</strong> List of Out() instances</li>
<li><strong>expanded_inputs:</strong> equals to inputs plus sharedvariables</li>
<li><strong>fgraph:</strong> FunctionGraph that represents the function it creates.</li>
<li><strong>Linker:</strong> Linker that link storage and apply method to create a <code>fn</code>. By default, <code>FAST_RUN</code> mode use <code>VM_Linker</code> , <code>FAST_COMPILE</code> uses <code>PerformLinker</code>.</li>
<li><strong>Optimizer, mode, profile &hellip;</strong>: some configuration that has less to do with my job</li>
</ul>


<p>METHOD:</p>

<ul>
<li><strong>create(input_storages):</strong> Given input_storages(by default, list of In.value), start the linker and link the function using <code>Linker.make_thunk()</code> return a theano.function.</li>
</ul>


<hr />

<h3>Linker/VM</h3>

<pre><code>Linker is a class that allocate storage for allpy_nodes and link them together. Understanding Linker and FunctionGraph definitely helps understands how theano works. The core method of Linker is make_thunk(). 
</code></pre>

<p>PARAMS:</p>

<ul>
<li><strong>fgraph</strong>: <code>FunctionGraph</code> accpeted by <code>Linker.accept()</code>.</li>
<li><strong>allow_gc,recycle&hellip;</strong>: some configuration bools</li>
</ul>


<p>METHODS:</p>

<ul>
<li><strong>make_thunk/all&hellip; :</strong>  <code>make_thunk()</code> is defined in class <code>Linker</code>. It calls method <code>make_all()</code>. Every subclass of linker will have slightly different implementation of <code>make_all()</code>. Bascially, at first, <code>make_all()</code> will toposort a fgraph, to acquire the <code>order</code> that apply_nodes should be executed. Next, it will call <code>Op.make_thunk()</code>, whick return a function. This function take input_storage of node, apply computation on them, and put result on output storage. Meanwhile, <code>make_all()</code> will allocate storage for all variables . Same variables in different node will have same storages. This is done by a dict <code>sotarge_map</code> that map variable to storage. At last, Linker return a function that executes list of thunks in certain order to acquire function outputs data.</li>
</ul>


<h3>Storage</h3>

<pre><code>Storage is quite a tricky thing in theano. Theano use a list with one element to be a storage. The element is true data. But all object only refer to the list. 
The list works like a pointer. When some objects refer to a storage, they refers to the list, not the true data. Therefore, modifying the data of storage will not change this reference. By doing this, theano can access and modify storage data from several places without change the reference relationship.
</code></pre>

<hr />

<h3>FunctionGraph</h3>

<pre><code>A representation of the computational graph of a function. It stores given the input and output variables of one function, by calling node.input and variable.owner recursively we can get the whole graph 
</code></pre>

<p>PARAMS:</p>

<ul>
<li><strong>features:</strong> Still Don&rsquo;t understand now, ignore it.</li>
<li><strong>input/output:</strong> List of input/output variabls.</li>
<li><strong>variables:</strong> Set of variables( all variables in the subgraph)</li>
<li><strong>apply_nodes:</strong> Set of apply_nodes in the subgraph defined by inputs and outputs</li>
</ul>


<p>METHODS</p>

<ul>
<li><code>__import_r__</code> and <code>__import__()</code>: import variable and apply_node to this fgraph.</li>
<li><code>clone_get_equiv</code> : Clone fgraph. Return new fgraph and a dict that map old variables to new variables.</li>
<li><code>replace()</code> : Replace all certain variables in fgraph by given new variables.</li>
</ul>


<hr />

<h2>How theano work?( Simplified version )</h2>

<h3>Without update:</h3>

<p>1.Input Variables will be wraped and become <code>In()</code>s. Each <code>In()</code> contains variable, it&rsquo;s value( defaults is none ) as well as some other configuration.
2.Generate fgraph by input and output variables, and then optimize it.
3.Linker toposorts fgraph to get an <code>order</code> of apply_nodes.Next, Linker allocates storages and links function based on this <code>order</code>.
4.Done</p>

<h3>With update:</h3>

<p>Update is given by a dict <code>{ ori_var:update_var ... }</code>. <code>Ori_var</code> is limited to be an SharedVariable therefore it will transfer into <code>In()</code> and become the input of this function. <code>update_var</code> will be add into the output of fgraph. Everytime a function called, the function  extract the storage of <code>update_var</code> and use it to set the value of corresponding input.</p>

<hr />

<h2>How to implement the share_memory feature?</h2>

<p>This is simple after understand how theano works. I implements it following sevaral steps:
1. Copy <code>In()</code> and <code>Out()</code> instances in Maker
2. Copy fgraph and get the dict <code>equiv</code> that map old variables to new variables
3. Copy old storage_map in <code>Function.fn.storage_map</code>
4. Modify copied storage_map accord to equiv, so that in the copied storage_map, new variables are mapped to old storage if memory need to be shared.
5. Reinitialize the maker, linke the function using the copied storage_map
6. Done</p>

<hr />

<p>Ok, basically this is the report of this week&rsquo;s work. Now I need to figure out how to implement the following features.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First Gift From Google]]></title>
    <link href="http://chienlima.github.io/blog/2015/05/16/first-gift-from-google/"/>
    <updated>2015-05-16T16:12:52+08:00</updated>
    <id>http://chienlima.github.io/blog/2015/05/16/first-gift-from-google</id>
    <content type="html"><![CDATA[<p>Several days a ago, I reveived a Fedex package. When I opened it &hellip; Bomb!</p>

<h4>Payoneer pre-paid MasterCard with Google icon on it!</h4>

<p><img src="/images/GSoCMasterCard.jpg" width="512" height="512" title="&lsquo;image&rsquo; &lsquo;images&rsquo;" ></p>

<p>Good looking card. I guass someone will regret for using existing bank account.
Also this is my first own credit card. Finally I can make payment without a phone from my dad :)</p>

<p>Google is ready to pay me now. &ldquo;Are you OK?&rdquo;( Leijun&rsquo;s &lsquo;Chinglish&rsquo; )</p>

<hr />

<p>Kinda occupied in the last week. Luckily, I finished those buinesses. And now I am back again.
The first feature I will add to theano is a function that allow user to make a copy of function and allow functions run multi-theadedly. There exist two similar features: <code>pickle()</code> and <code>copy()</code> of a function. To figure how I need to work. I need to take 3 steps as preparation:</p>

<ul>
<li>Look into the code and see how function is generated <code>Done</code></li>
<li>Look into the code and understand <code>Function</code>, <code>FunctionMaker</code>, <code>Linker</code> and <code>FunctionGraph</code>. <code>next</code></li>
<li>Have a look at <code>pickle</code> and <code>copy()</code>, use them, figure out how them work and the differneces. Then think about my own idea.</li>
</ul>


<p>Ok, now I need to go and take the step two now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First Look Into Theano Core]]></title>
    <link href="http://chienlima.github.io/blog/2015/05/07/first-look-into-theano-core/"/>
    <updated>2015-05-07T11:08:32+08:00</updated>
    <id>http://chienlima.github.io/blog/2015/05/07/first-look-into-theano-core</id>
    <content type="html"><![CDATA[<p>It&rsquo;s been a week and a half since google-melange anounced the accepted student for google summer of code. I was luckcy enough to be accepted by Theano &ndash; sub-foundation of Python organization, to help them add new features: Allow user to modify compiled function. As scheduled, from 27th April to 23rd May is the community bounding period. During these days I ought to get familiar with Theano core code and Theano dev community.</p>

<p>Before the application started, I&rsquo;ve dived into Theano cored and got the basic idea of what I&#8217;am going to do. However, to make the idea more clear and to fit the requirement that student should post every week about their progress. I decide to write two post about Theano core &ndash; about how theano work. This is the first post. This post will talk about what is a function? And how a function is generate.</p>

<h2>How a function is generated?</h2>

<p> Just recall how we compiled a function <code>func = theano.function( [ inputs ], output )</code>, we can know that we should start out journey from method  <code>function()</code>, which locates in  <code>theano/compile/founction.py</code>.<br/>
 In method <code>function()</code>, after some data verification, it will call <code>orig_func()</code> or <code>pfunc()</code> which return a <code>function</code> that user will get. Since <code>pfunc()</code> will also call <code>orig_func()</code>, we are going to look into <code>pfunc()</code> first.</p>

<h3>pfunc.py</h3>

<p> <code>pfunc()</code> have two major tasks:</p>

<ul>
<li>Transfer input_variable into <code>In()</code> instances. So does <code>shared_variable</code>. ( In function graph,  SharedVariabls are treated as input, updates are treated as output ).</li>
<li>Rebuild computational graph using <code>updates</code> and <code>inputs</code>, transform output into <code>Out</code>  instances.</li>
</ul>


<pre><code class="python">
def pfunc( ... some arguments ... ):

    # Clones the replacements named in the givens argument, and points each Var1 to
    # the clone of Var2.
    # Transform params into theano.compile.In objects.
    inputs = [_pfunc_param_to_in(p, allow_downcast=allow_input_downcast)
                for p in params]

    #  clones the outputs and the update expressions.  This rebuilds a computation graph
    # from the inputs and the givens. ( Irrelative to me. Pass )

    output_vars = rebuild_collect_shared(outputs,
                                             in_variables,
                                             replace=givens,
                                             updates=updates,
                                             rebuild_strict=rebuild_strict,
                                             copy_inputs_over=True,
                                             no_default_updates=no_default_updates)
    # extracting the arguments
    input_variables, cloned_outputs, other_stuff = output_vars
    clone_d, update_d, update_expr, shared_inputs = other_stuff

    for i, iv in zip(inputs, input_variables):
        i.variable = iv

    for sv in shared_inputs:
        # pass value of None here
        # value will be stored in the resulting functions' defaults list
        # but since the value of shared variables never needs to be refed, it is not needed
        if sv in update_d:
            si = In(variable=sv, value=sv.container, mutable=True,
                    borrow=True, update=update_d[sv], shared=True)
        else:
            si = In(variable=sv, value=sv.container,
                    mutable=False, borrow=True, shared=True)
        inputs.append(si)

    return orig_function(inputs, cloned_outputs, mode,
            accept_inplace=accept_inplace, name=name, profile=profile,
            on_unused_input=on_unused_input, output_keys=output_keys
</code></pre>

<hr />

<h3>orig_func():</h3>

<p>Now it time for a look into <code>orig_func()</code>.  <code>orig_func()</code> will again makes sure that inputs and outputs are transformed into <code>In</code> an <code>Out</code>. And then it will use <code>create</code> method in <code>FunctionMaker</code> to make a function, which will be return.</p>

<pre><code class="python">def orig_function(inputs, outputs, mode=None, accept_inplace=False,
                  name=None, profile=None, on_unused_input=None,
                  output_keys=None):

    # conver input variable into instances of In() instances
    inputs = map(convert_function_input, inputs)

    # so do outputs
    if outputs is not None:
        if isinstance(outputs, (list, tuple)):
            outputs = map(FunctionMaker.wrap_out, outputs)
        else:
            outputs = FunctionMaker.wrap_out(outputs)

    # In()s and Out()s will be passed into FunctionMaker and a function will be create from it by calling create() method.
    fn = Maker(inputs,
                   outputs,
                   mode,
                   accept_inplace=accept_inplace,
                   profile=profile,
                   on_unused_input=on_unused_input,
                   output_keys = output_keys).create(
                       defaults)         #     ^^^^ 
</code></pre>

<hr />

<h3>FunctionMaker:</h3>

<p> <code>FunctionMaker.__init()__</code> is where <code>fgraph</code> is extracted and optimized. <code>FuncitonMaker.create()</code> is where <code>function</code> will be compiled and linked. In fact, <code>FunctionMaker.linker.make_thunk()</code> is where <code>function</code> is linked.</p>

<pre><code class="python">class FunctionMaker:
    def __init__( ...args... ):
        # again, make sure that input/output are tranformed into In and Out
        inputs, outputs = map(self.wrap_in, inputs), map(self.wrap_out, outputs)

        # ???
        _inputs = gof.graph.inputs([o.variable for o in outputs] + [i.update for i in inputs if getattr(i, 'update', False)])

        # make indices ... which is useless
        indices = [[input] + self.expand_in(input, _inputs) for input in inputs]

        # get fgraph
        if fgraph is Node:
            fgraph, additional_outputs = std_fgraph(inputs, outputs, accept_inplace)
        else:
            _, additional_outputs = std_fgraph(inputs, outputs, accept_inplace)
        self.fgraph = fgraph

        # fetch optimizor and linker
        optimizer, linker = mode.optimizer, copy.copy(mode.linker)

        # optimize fgraph
        # if need_opt:
            # optimization code here

        # linker accept fgraph 
        if no_borrow:
            self.linker = linker.accept(fgraph, no_recycling=infer_reuse_pattern(fgraph, no_borrow))
        else:
            self.linker = linker.accept(fgraph)

        if hasattr(linker, 'accept_var_updates'):
            # hacky thing so VMLinker knows about updates
            self.linker.accept_var_updates(
                    fgraph_updated_vars(fgraph, inputs))

        # some other configeration here
        # ...

    def create(self, input_storage=None, trustme=False):
    """
    Create a function.

    Input storage is the 'value' attribute of each In instances
    """

        # construct input_storage_list and default list
        for i, ((input, indices, subinputs), input_storage_i) in enumerate(zip(self.indices, input_storage)):
            # a lot of codes here.

        """
        Q: What's indices?
        List of (SymbolicInput, incide, [SymbolicInput..]). The first one is the 
        input vaiable; the incide is the index of the input in the input list; 
        the [SymIn...] the relevant input(?); 
        According to the document, the last two is deprecated. So it can be regarded as list of SymbolicInput.

        Q: What's defaults?
        A: List of 3-tuples. Each tuple corresponds to one input_storage. 
        ( 
          Bool: Is this input required at each function call?,  
          Bool: Should this inputs value be reverted to default value after each call? 
          AnyType: The value(storage) associated with this input.
        )
        """    

        # call make_thunk() from linker and get fn
        try:
            theano.config.traceback.limit = 0
            _fn, _i, _o = self.linker.make_thunk(input_storage=input_storage_lists)
            # ^   ^   ^ =&gt; (function, input_containers, output_containers)
            # where function is a thunk that operates on the returned variables.
            # Because the map_storag() in make_thunk()
            # from here on, the input/output_storage represent all I/O of all relative nodes
            # ALso, storage is container, Instead of SymbolicKit
        finally:
            theano.config.traceback.limit = limit_orig

        # get a function, here function_builder() is the constructor
        # of class Function.
        fn = self.function_builder(_fn, _i, _o, self.indices, self.outputs,
                    defaults, self.unpack_single, self.return_none, self.output_keys, self)
        return fn
</code></pre>

<hr />

<h2>What&rsquo;s <code>theano.function</code>?</h2>

<p>Each function is a callable object.  <code>theano.function</code> is not a python function. Instead, it a class with method <code>__call__()</code>.  Every funciton stores its own fgraph, maker, storages and many other configurations. However, the core of a function is a function <code>fn()</code> returned by <code>linker.make_thunk()</code>. Every time a function is called, it will first verify the input data, and then call <code>self.fn()</code> to get output values.</p>

<hr />

<p>Now I know how is a function borned. Also, I know that to complete my missions, I need to focus more on <code>FunctionMaker</code> and <code>Function</code> rather that <code>orig_func()</code> and <code>pfunc()</code>. However, there still exist some question, such as: What does <code>make_thunk()</code> do? and What is <code>In()</code>, <code>Out()</code> and <code>container</code>? In the next post, I will have a look at this and other relative data structures.</p>
]]></content>
  </entry>
  
</feed>
